{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01bbfb64-22bb-43b8-b0ad-d83a0dc0c954",
   "metadata": {},
   "source": [
    "# RAG testset generation\n",
    "\n",
    "**Purpose:** Generate test questions for RAG Evaluation\n",
    "\n",
    "---\n",
    "**Copyright (c) 2025 Michael Powers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6253d65a-16cb-421d-92df-48d69cb2ddc6",
   "metadata": {},
   "source": [
    "# Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b225242-6547-41a5-990d-4b605fb43383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from llama_index.core import Document\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "import logging\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "\n",
    "# For Hugging Face Dataset format\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be9152d3-47a4-44e8-9934-ce615fe6e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_model = 'gemini-2.5-flash-lite-preview-06-17'\n",
    "api_key=\"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9a58a2-fc52-491e-9e78-8235d883956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfb17793-1fa1-4848-b99d-1cff13ef2a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "CHROMA_DB_PATH = \"../application/chroma_db\"\n",
    "SCHEMA_COLLECTION_NAME = \"sql_schema_metadata_collection\"\n",
    "BUSINESS_TERMS_COLLECTION_NAME = \"business_terms_collection\"\n",
    "HUGGINGFACE_EMBEDDING_MODEL_NAME = \"BAAI/bge-small-en-v1.5\" # needs to match\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752a98ec-061c-4125-9e35-7449b0bf4562",
   "metadata": {},
   "source": [
    "# LLM Caller Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d47fd52b-d90b-4b4b-9457-b0bfd44b79fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gemini_json(prompt, use_json=True, model='models/gemini-2.0-flash-lite'):\n",
    "    import os\n",
    "    import google.generativeai as genai\n",
    "    genai.configure(api_key=api_key)\n",
    "    model = genai.GenerativeModel(model)\n",
    "    if use_json:\n",
    "        generation_config = genai.GenerationConfig(response_mime_type=\"application/json\")\n",
    "        response = model.generate_content(prompt, generation_config=generation_config)\n",
    "    else:\n",
    "        response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8fb60c5-e058-42ba-87d2-79c29f31d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(context_text):\n",
    "    prompt = f\"\"\"\n",
    "Based on the following context, generate ONE question about the content and its corresponding ground truth answer.\n",
    "The question should be concise and directly answerable from the provided context.\n",
    "The ground truth answer should be derived directly and accurately from the context.\n",
    "Focus on questions that someone building a SQL query or understanding business terms would ask.\n",
    "\n",
    "Output the question and answer in a JSON format with keys \"question\" and \"ground_truth_answer\".\n",
    "Ensure the \"ground_truth_answer\" is a string, even if it contains a list or structured information.\n",
    "\n",
    "Context:\n",
    "\n",
    "{context_text}\n",
    "\n",
    "Example JSON format:\n",
    "```json\n",
    "{{\n",
    "  \"question\": \"What is the primary key of the 'Customers' table?\",\n",
    "  \"ground_truth_answer\": \"The primary key of the 'Customers' table is 'customer_id'.\"\n",
    "}}\n",
    "```\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8986a0-de25-4c24-9f81-d23df41c46d7",
   "metadata": {},
   "source": [
    "# Get RAG Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91dfa7a6-b26f-46a1-b376-f3645bd0bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_model():\n",
    "    return HuggingFaceEmbedding(model_name=HUGGINGFACE_EMBEDDING_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eb744f7-7725-404d-b922-df36e56ffd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_nodes_from_chroma(collection_name: str) -> List[Document]:\n",
    "    logger.info(f\"Retrieving all nodes from collection: {collection_name} for testset generation...\")\n",
    "    try:\n",
    "        db = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "        chroma_collection = db.get_or_create_collection(collection_name)\n",
    "\n",
    "        all_ids = chroma_collection.get(ids=chroma_collection.get()['ids'])['ids']\n",
    "        results = chroma_collection.get(ids=all_ids, include=['documents', 'metadatas'])\n",
    "\n",
    "        documents = []\n",
    "        for i in range(len(results['ids'])):\n",
    "            raw_text_from_chroma = results['documents'][i]\n",
    "            metadata = results['metadatas'][i]\n",
    "            doc = Document(text=raw_text_from_chroma, metadata=metadata, id_=results['ids'][i])\n",
    "            documents.append(doc)\n",
    "        logger.info(f\"Retrieved {len(documents)} nodes from {collection_name}.\")\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error retrieving nodes from ChromaDB collection {collection_name}: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a775970-3508-4468-b186-bda3379af76e",
   "metadata": {},
   "source": [
    "# question gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26fdbf94-af03-4cd7-af1e-10c6250b037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(documents, test_set_size = 15, model=gemini_model, rpm_limit=15):\n",
    "    import random\n",
    "\n",
    "    RPM_LIMIT = rpm_limit\n",
    "    MAX_RETRIES = 5\n",
    "    BASE_SLEEP_TIME = 4.5\n",
    "    \n",
    "    generated_data_for_ragas = []\n",
    "    num_generated_questions = 0\n",
    "\n",
    "    if test_set_size < len(documents):\n",
    "        documents_to_process = random.sample(documents, test_set_size)\n",
    "    else:\n",
    "        documents_to_process = documents\n",
    "\n",
    "    # Counter for API calls made within the current minute\n",
    "    requests_in_minute = 0\n",
    "    start_time_minute = time.time()\n",
    "    \n",
    "    \n",
    "    for i, doc in enumerate(documents_to_process):\n",
    "        if num_generated_questions >= test_set_size:\n",
    "            break\n",
    "        context_text = doc.get_content()\n",
    "        # Ensure context is not empty\n",
    "        if not context_text.strip():\n",
    "            logger.warning(f\"Skipping empty context for document {doc.id_}\")\n",
    "            continue\n",
    "        logger.info(f\"Generating question for document {i+1}/{len(documents_to_process)}...\")\n",
    "        \n",
    "        retries = 0\n",
    "        while retries < MAX_RETRIES:\n",
    "            if num_generated_questions >= test_set_size:\n",
    "                break\n",
    "\n",
    "            # Check RPM limit\n",
    "            current_time = time.time()\n",
    "            if current_time - start_time_minute >= 60:\n",
    "                requests_in_minute = 0\n",
    "                start_time_minute = current_time\n",
    "\n",
    "            if requests_in_minute >= RPM_LIMIT:\n",
    "                wait_time = 60 - (current_time - start_time_minute)\n",
    "                print(f\"Rate limit hit. Waiting for {wait_time:.2f} seconds...\")\n",
    "                time.sleep(wait_time + 1)\n",
    "                requests_in_minute = 0\n",
    "                start_time_minute = time.time()\n",
    "                \n",
    "            try: # RESPONSE\n",
    "                prompt = get_prompt(context_text)\n",
    "                response = ask_gemini_json(prompt, use_json=True, model=model)\n",
    "                response = response.strip()\n",
    "                if response.startswith(\"```json\") and response.endswith(\"```\"):\n",
    "                    response = response[len(\"```json\"): -len(\"```\")].strip()\n",
    "                elif response.startswith(\"```\") and response.endswith(\"```\"):\n",
    "                    response = response[len(\"```\"): -len(\"```\")].strip()\n",
    "                generated_text = response\n",
    "                try: # PARSE JSON\n",
    "                    qa_pair = json.loads(generated_text)\n",
    "                    question = qa_pair.get(\"question\")\n",
    "                    ground_truth_answer = qa_pair.get(\"ground_truth_answer\")\n",
    "                \n",
    "                    if question and ground_truth_answer:\n",
    "                        # Append the original document's text as contexts\n",
    "                        # Ragas expects a list of strings for 'contexts'\n",
    "                        generated_data_for_ragas.append({\n",
    "                            \"question\": question,\n",
    "                            \"ground_truth_answers\": [ground_truth_answer], # Ragas expects a list\n",
    "                            \"contexts\": [context_text] # Use the full context that the Q&A was derived from\n",
    "                        })\n",
    "                        num_generated_questions += 1\n",
    "                        logger.info(f\"Generated Q&A pair {num_generated_questions}/{test_set_size}\")\n",
    "                    else:\n",
    "                        logger.warning(f\"LLM generated incomplete JSON for document {doc.id_}: {generated_text}\")\n",
    "                except json.JSONDecodeError:\n",
    "                    logger.warning(f\"LLM did not generate valid JSON for document {doc.id_}. Response: {generated_text[:500]}...\")\n",
    "                break # Success, break out of retry loop\n",
    "            except Exception as e:     \n",
    "                retries += 1\n",
    "                sleep_duration = BASE_SLEEP_TIME * (2 ** (retries - 1)) + random.uniform(0, 1)\n",
    "                logger.warning(f\"API Error : {e}. Retrying in {sleep_duration:.2f}s... (Attempt {retries}/{MAX_RETRIES})\")\n",
    "                time.sleep(sleep_duration)\n",
    "\n",
    "            if retries == MAX_RETRIES:\n",
    "                logger.error(f\"Failed to process after {MAX_RETRIES} retries. Skipping.\")\n",
    "                continue # Continue to next document even if one fails\n",
    "    #### DONE LOOPING\n",
    "    \n",
    "    if not generated_data_for_ragas:\n",
    "        logger.error(\"No questions were successfully generated. Please review logs and configuration.\")\n",
    "        exit(1)\n",
    "\n",
    "    logger.info(f\"Successfully generated {len(generated_data_for_ragas)} Q&A pairs.\")\n",
    "    hf_dataset = Dataset.from_list(generated_data_for_ragas)\n",
    "\n",
    "    ### SAVE TO JSON FILE ###\n",
    "    output_filename = f\"ragas_custom_testset_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    hf_dataset.to_json(output_filename, indent=4)\n",
    "    logger.info(f\"Generated RAG evaluation testset saved to: {output_filename}\")\n",
    "\n",
    "    print(f\"\\nSuccessfully generated a RAG evaluation testset with {len(hf_dataset)} questions.\")\n",
    "    print(\"Here's a sample of the generated questions and contexts:\")\n",
    "    for i, entry in enumerate(hf_dataset):\n",
    "        if i >= 3: # Print first 3 samples\n",
    "            break\n",
    "        print(f\"\\n--- Sample {i+1} ---\")\n",
    "        print(f\"Question: {entry['question']}\")\n",
    "        print(f\"Ground Truth Answer: {entry['ground_truth_answers'][0]}\") \n",
    "        print(f\"Contexts ({len(entry['contexts'])} nodes):\")\n",
    "        for j, context_text in enumerate(entry['contexts']):\n",
    "            if j < 1: # Print only the first context for brevity\n",
    "                print(f\"  - Context {j+1}: {context_text[:300]}...\") # Truncate for display\n",
    "            else:\n",
    "                print(f\"  - ... ({len(entry['contexts']) - 1} more contexts)\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c414f4-dfe5-432f-8777-dd301c3a5f34",
   "metadata": {},
   "source": [
    "# Prep and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38e981c4-d0af-4252-b9e9-2cf4e583d22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 08:21:42,828 - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "2025-07-20 08:21:45,418 - INFO - 2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2025-07-20 08:21:45,432 - INFO - Retrieving all nodes from collection: sql_schema_metadata_collection for testset generation...\n",
      "2025-07-20 08:21:45,651 - INFO - Retrieved 134 nodes from sql_schema_metadata_collection.\n",
      "2025-07-20 08:21:45,652 - INFO - Retrieving all nodes from collection: business_terms_collection for testset generation...\n",
      "2025-07-20 08:21:45,813 - INFO - Retrieved 1 nodes from business_terms_collection.\n"
     ]
    }
   ],
   "source": [
    "#create embedding\n",
    "embeddings_model = get_embedding_model()\n",
    "\n",
    "#retrieve and combine documents\n",
    "schema_documents = get_all_nodes_from_chroma(SCHEMA_COLLECTION_NAME)\n",
    "business_terms_documents = get_all_nodes_from_chroma(BUSINESS_TERMS_COLLECTION_NAME)\n",
    "all_retrieved_documents = schema_documents + business_terms_documents\n",
    "\n",
    "if not all_retrieved_documents:\n",
    "    logger.error(\"No source documents found in ChromaDB collections. Cannot generate test set. Make sure ingest.py ran successfully.\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "862baa54-713f-4ea0-95c8-a0d0bacb7274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 08:28:22,702 - INFO - Generating question for document 1/50...\n",
      "2025-07-20 08:28:23,539 - INFO - Generated Q&A pair 1/50\n",
      "2025-07-20 08:28:23,539 - INFO - Generating question for document 2/50...\n",
      "2025-07-20 08:28:24,718 - INFO - Generated Q&A pair 2/50\n",
      "2025-07-20 08:28:24,719 - INFO - Generating question for document 3/50...\n",
      "2025-07-20 08:28:25,633 - INFO - Generated Q&A pair 3/50\n",
      "2025-07-20 08:28:25,634 - INFO - Generating question for document 4/50...\n",
      "2025-07-20 08:28:26,332 - INFO - Generated Q&A pair 4/50\n",
      "2025-07-20 08:28:26,333 - INFO - Generating question for document 5/50...\n",
      "2025-07-20 08:28:27,159 - INFO - Generated Q&A pair 5/50\n",
      "2025-07-20 08:28:27,160 - INFO - Generating question for document 6/50...\n",
      "2025-07-20 08:28:28,896 - INFO - Generated Q&A pair 6/50\n",
      "2025-07-20 08:28:28,897 - INFO - Generating question for document 7/50...\n",
      "2025-07-20 08:28:31,862 - INFO - Generated Q&A pair 7/50\n",
      "2025-07-20 08:28:31,863 - INFO - Generating question for document 8/50...\n",
      "2025-07-20 08:28:33,694 - INFO - Generated Q&A pair 8/50\n",
      "2025-07-20 08:28:33,695 - INFO - Generating question for document 9/50...\n",
      "2025-07-20 08:28:34,425 - INFO - Generated Q&A pair 9/50\n",
      "2025-07-20 08:28:34,426 - INFO - Generating question for document 10/50...\n",
      "2025-07-20 08:28:35,114 - INFO - Generated Q&A pair 10/50\n",
      "2025-07-20 08:28:35,115 - INFO - Generating question for document 11/50...\n",
      "2025-07-20 08:28:35,911 - INFO - Generated Q&A pair 11/50\n",
      "2025-07-20 08:28:35,911 - INFO - Generating question for document 12/50...\n",
      "2025-07-20 08:28:36,646 - INFO - Generated Q&A pair 12/50\n",
      "2025-07-20 08:28:36,646 - INFO - Generating question for document 13/50...\n",
      "2025-07-20 08:28:37,473 - INFO - Generated Q&A pair 13/50\n",
      "2025-07-20 08:28:37,474 - INFO - Generating question for document 14/50...\n",
      "2025-07-20 08:28:38,288 - INFO - Generated Q&A pair 14/50\n",
      "2025-07-20 08:28:38,288 - INFO - Generating question for document 15/50...\n",
      "2025-07-20 08:28:39,107 - INFO - Generated Q&A pair 15/50\n",
      "2025-07-20 08:28:39,107 - INFO - Generating question for document 16/50...\n",
      "2025-07-20 08:28:39,824 - INFO - Generated Q&A pair 16/50\n",
      "2025-07-20 08:28:39,824 - INFO - Generating question for document 17/50...\n",
      "2025-07-20 08:28:40,273 - WARNING - API Error : 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 19\n",
      "}\n",
      "]. Retrying in 5.08s... (Attempt 1/5)\n",
      "2025-07-20 08:28:45,778 - WARNING - API Error : 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 14\n",
      "}\n",
      "]. Retrying in 9.18s... (Attempt 2/5)\n",
      "2025-07-20 08:28:55,488 - WARNING - API Error : 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 4\n",
      "}\n",
      "]. Retrying in 18.67s... (Attempt 3/5)\n",
      "2025-07-20 08:29:14,586 - WARNING - API Error : 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 45\n",
      "}\n",
      "]. Retrying in 36.39s... (Attempt 4/5)\n",
      "2025-07-20 08:29:51,734 - INFO - Generated Q&A pair 17/50\n",
      "2025-07-20 08:29:51,735 - INFO - Generating question for document 18/50...\n",
      "2025-07-20 08:29:52,531 - INFO - Generated Q&A pair 18/50\n",
      "2025-07-20 08:29:52,531 - INFO - Generating question for document 19/50...\n",
      "2025-07-20 08:29:53,359 - INFO - Generated Q&A pair 19/50\n",
      "2025-07-20 08:29:53,360 - INFO - Generating question for document 20/50...\n",
      "2025-07-20 08:29:54,150 - INFO - Generated Q&A pair 20/50\n",
      "2025-07-20 08:29:54,151 - INFO - Generating question for document 21/50...\n",
      "2025-07-20 08:29:54,847 - INFO - Generated Q&A pair 21/50\n",
      "2025-07-20 08:29:54,848 - INFO - Generating question for document 22/50...\n",
      "2025-07-20 08:29:56,521 - INFO - Generated Q&A pair 22/50\n",
      "2025-07-20 08:29:56,521 - INFO - Generating question for document 23/50...\n",
      "2025-07-20 08:29:57,133 - INFO - Generated Q&A pair 23/50\n",
      "2025-07-20 08:29:57,134 - INFO - Generating question for document 24/50...\n",
      "2025-07-20 08:29:57,958 - INFO - Generated Q&A pair 24/50\n",
      "2025-07-20 08:29:57,958 - INFO - Generating question for document 25/50...\n",
      "2025-07-20 08:29:58,675 - INFO - Generated Q&A pair 25/50\n",
      "2025-07-20 08:29:58,675 - INFO - Generating question for document 26/50...\n",
      "2025-07-20 08:29:59,438 - INFO - Generated Q&A pair 26/50\n",
      "2025-07-20 08:29:59,439 - INFO - Generating question for document 27/50...\n",
      "2025-07-20 08:30:00,142 - INFO - Generated Q&A pair 27/50\n",
      "2025-07-20 08:30:00,142 - INFO - Generating question for document 28/50...\n",
      "2025-07-20 08:30:00,990 - INFO - Generated Q&A pair 28/50\n",
      "2025-07-20 08:30:00,990 - INFO - Generating question for document 29/50...\n",
      "2025-07-20 08:30:01,829 - INFO - Generated Q&A pair 29/50\n",
      "2025-07-20 08:30:01,829 - INFO - Generating question for document 30/50...\n",
      "2025-07-20 08:30:02,771 - INFO - Generated Q&A pair 30/50\n",
      "2025-07-20 08:30:02,771 - INFO - Generating question for document 31/50...\n",
      "2025-07-20 08:30:03,489 - INFO - Generated Q&A pair 31/50\n",
      "2025-07-20 08:30:03,489 - INFO - Generating question for document 32/50...\n",
      "2025-07-20 08:30:04,104 - INFO - Generated Q&A pair 32/50\n",
      "2025-07-20 08:30:04,105 - INFO - Generating question for document 33/50...\n",
      "2025-07-20 08:30:04,806 - INFO - Generated Q&A pair 33/50\n",
      "2025-07-20 08:30:04,807 - INFO - Generating question for document 34/50...\n",
      "2025-07-20 08:30:05,218 - WARNING - API Error : 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 54\n",
      "}\n",
      "]. Retrying in 4.60s... (Attempt 1/5)\n",
      "2025-07-20 08:30:10,243 - WARNING - API Error : 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "]. Retrying in 9.91s... (Attempt 2/5)\n",
      "2025-07-20 08:30:20,999 - INFO - Generated Q&A pair 34/50\n",
      "2025-07-20 08:30:21,000 - INFO - Generating question for document 35/50...\n",
      "2025-07-20 08:30:21,419 - WARNING - API Error : 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 38\n",
      "}\n",
      "]. Retrying in 5.49s... (Attempt 1/5)\n",
      "2025-07-20 08:30:27,757 - INFO - Generated Q&A pair 35/50\n",
      "2025-07-20 08:30:27,757 - INFO - Generating question for document 36/50...\n",
      "2025-07-20 08:30:28,576 - INFO - Generated Q&A pair 36/50\n",
      "2025-07-20 08:30:28,576 - INFO - Generating question for document 37/50...\n",
      "2025-07-20 08:30:29,395 - INFO - Generated Q&A pair 37/50\n",
      "2025-07-20 08:30:29,395 - INFO - Generating question for document 38/50...\n",
      "2025-07-20 08:30:30,938 - INFO - Generated Q&A pair 38/50\n",
      "2025-07-20 08:30:30,939 - INFO - Generating question for document 39/50...\n",
      "2025-07-20 08:30:31,779 - INFO - Generated Q&A pair 39/50\n",
      "2025-07-20 08:30:31,779 - INFO - Generating question for document 40/50...\n",
      "2025-07-20 08:30:32,612 - INFO - Generated Q&A pair 40/50\n",
      "2025-07-20 08:30:32,612 - INFO - Generating question for document 41/50...\n",
      "2025-07-20 08:30:33,376 - INFO - Generated Q&A pair 41/50\n",
      "2025-07-20 08:30:33,377 - INFO - Generating question for document 42/50...\n",
      "2025-07-20 08:30:34,214 - INFO - Generated Q&A pair 42/50\n",
      "2025-07-20 08:30:34,215 - INFO - Generating question for document 43/50...\n",
      "2025-07-20 08:30:35,028 - INFO - Generated Q&A pair 43/50\n",
      "2025-07-20 08:30:35,029 - INFO - Generating question for document 44/50...\n",
      "2025-07-20 08:30:35,847 - INFO - Generated Q&A pair 44/50\n",
      "2025-07-20 08:30:35,848 - INFO - Generating question for document 45/50...\n",
      "2025-07-20 08:30:36,663 - INFO - Generated Q&A pair 45/50\n",
      "2025-07-20 08:30:36,664 - INFO - Generating question for document 46/50...\n",
      "2025-07-20 08:30:37,411 - INFO - Generated Q&A pair 46/50\n",
      "2025-07-20 08:30:37,412 - INFO - Generating question for document 47/50...\n",
      "2025-07-20 08:30:38,202 - INFO - Generated Q&A pair 47/50\n",
      "2025-07-20 08:30:38,203 - INFO - Generating question for document 48/50...\n",
      "2025-07-20 08:30:38,919 - INFO - Generated Q&A pair 48/50\n",
      "2025-07-20 08:30:38,920 - INFO - Generating question for document 49/50...\n",
      "2025-07-20 08:30:39,735 - INFO - Generated Q&A pair 49/50\n",
      "2025-07-20 08:30:39,736 - INFO - Generating question for document 50/50...\n",
      "2025-07-20 08:30:40,554 - INFO - Generated Q&A pair 50/50\n",
      "2025-07-20 08:30:40,555 - INFO - Successfully generated 50 Q&A pairs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422289cabbfa42dd8f15b6d7b5e77ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 08:30:40,577 - INFO - Generated RAG evaluation testset saved to: ragas_custom_testset_20250720_083040.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully generated a RAG evaluation testset with 50 questions.\n",
      "Here's a sample of the generated questions and contexts:\n",
      "\n",
      "--- Sample 1 ---\n",
      "Question: What does the 'PID' column in the 'M_Director' table represent?\n",
      "Ground Truth Answer: The 'PID' column in the 'M_Director' table represents the person ID of the director.\n",
      "Contexts (1 nodes):\n",
      "  - Context 1: Database: DB_IMDB\n",
      "Table: M_Director\n",
      "Columns:\n",
      "  index (INTEGER)\n",
      "  MID (TEXT)\n",
      "  PID (TEXT)\n",
      "  ID (INTEGER)\n",
      "Sample Rows:\n",
      "  {'index': 1046, 'MID': 'tt6080746', 'PID': 'nm0223606', 'ID': 1046}\n",
      "  {'index': 2699, 'MID': 'tt2962230', 'PID': 'nm0154269', 'ID': 2699}...\n",
      "\n",
      "--- Sample 2 ---\n",
      "Question: What is the name of the column that stores the quantity of items sold in kilograms?\n",
      "Ground Truth Answer: The column that stores the quantity of items sold in kilograms is 'qty_sold(kg)'.\n",
      "Contexts (1 nodes):\n",
      "  - Context 1: Database: bank_sales_trading\n",
      "Table: veg_txn_df\n",
      "Columns:\n",
      "  index (INTEGER)\n",
      "  txn_date (TEXT)\n",
      "  txn_time (TEXT)\n",
      "  item_code (INTEGER)\n",
      "  qty_sold(kg) (REAL)\n",
      "  unit_selling_px_rmb/kg (REAL)\n",
      "  sale/return (TEXT)\n",
      "  discount(%) (INTEGER)\n",
      "  day_of_week (TEXT)\n",
      "Sample Rows:\n",
      "  {'index': 231837, 'txn_date': '20...\n",
      "\n",
      "--- Sample 3 ---\n",
      "Question: What are the columns in the 'seats' table?\n",
      "Ground Truth Answer: The columns in the 'seats' table are 'aircraft_code', 'seat_no', and 'fare_conditions'.\n",
      "Contexts (1 nodes):\n",
      "  - Context 1: Database: Airlines\n",
      "Table: seats\n",
      "Columns:\n",
      "  aircraft_code (character(3))\n",
      "  seat_no (character varying(4))\n",
      "  fare_conditions (character varying(10))\n",
      "Sample Rows:\n",
      "  {'aircraft_code': 'SU9', 'seat_no': '1F', 'fare_conditions': 'Business'}\n",
      "  {'aircraft_code': '763', 'seat_no': '28B', 'fare_conditions': '...\n"
     ]
    }
   ],
   "source": [
    "generate_questions(all_retrieved_documents, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c685740-eb31-4b1f-80a6-a3eea07ec066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
